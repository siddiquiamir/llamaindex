{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa48fae1-16a4-4f63-99d6-8b465849de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset import download_llama_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9de50eb-0186-463d-ab52-a207d7745eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and install dependencies\n",
    "rag_dataset, documents = download_llama_dataset(\n",
    "  \"BlockchainSolanaDataset\", \"./solana\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4373fbc3-1848-456d-a9ef-80f3a3f49e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the key issues preventing the wide ad...</td>\n",
       "      <td>[From Bitcoin to Solana – Innovating Blockchai...</td>\n",
       "      <td>The key issues preventing the wide adoption of...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does blockchain technology provide data se...</td>\n",
       "      <td>[From Bitcoin to Solana – Innovating Blockchai...</td>\n",
       "      <td>Blockchain technology provides data security a...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the projected growth rate of the block...</td>\n",
       "      <td>[2 \\n \\nchain market size is expected to grow ...</td>\n",
       "      <td>The projected growth rate of the blockchain ma...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are some of the challenges facing enterpr...</td>\n",
       "      <td>[2 \\n \\nchain market size is expected to grow ...</td>\n",
       "      <td>Some of the challenges facing enterprise adopt...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the key issues that need to be addres...</td>\n",
       "      <td>[3 \\n \\nScalability.  Scalability  is the seco...</td>\n",
       "      <td>The key issues that need to be addressed in or...</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "      <td>ai (gpt-3.5-turbo)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  What are the key issues preventing the wide ad...   \n",
       "1  How does blockchain technology provide data se...   \n",
       "2  What is the projected growth rate of the block...   \n",
       "3  What are some of the challenges facing enterpr...   \n",
       "4  What are the key issues that need to be addres...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [From Bitcoin to Solana – Innovating Blockchai...   \n",
       "1  [From Bitcoin to Solana – Innovating Blockchai...   \n",
       "2  [2 \\n \\nchain market size is expected to grow ...   \n",
       "3  [2 \\n \\nchain market size is expected to grow ...   \n",
       "4  [3 \\n \\nScalability.  Scalability  is the seco...   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  The key issues preventing the wide adoption of...  ai (gpt-3.5-turbo)   \n",
       "1  Blockchain technology provides data security a...  ai (gpt-3.5-turbo)   \n",
       "2  The projected growth rate of the blockchain ma...  ai (gpt-3.5-turbo)   \n",
       "3  Some of the challenges facing enterprise adopt...  ai (gpt-3.5-turbo)   \n",
       "4  The key issues that need to be addressed in or...  ai (gpt-3.5-turbo)   \n",
       "\n",
       "             query_by  \n",
       "0  ai (gpt-3.5-turbo)  \n",
       "1  ai (gpt-3.5-turbo)  \n",
       "2  ai (gpt-3.5-turbo)  \n",
       "3  ai (gpt-3.5-turbo)  \n",
       "4  ai (gpt-3.5-turbo)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see some rows\n",
    "rag_dataset.to_pandas()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6716c5-e521-427c-9a25-392c7db5344a",
   "metadata": {},
   "source": [
    "- With documents, you can build your own RAG pipeline, to then predict and perform evaluations to compare against the benchmarks listed in the DatasetCard associated with the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "debfdeba-474e-424d-a760-974f0b9f76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdf709f7-5571-4d30-97b3-56eb5cc2f4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "HF_TOKEN = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c8fd17-79e8-4877-b25a-a6c52cb5f2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceInferenceAPI(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x0000029508FCE590>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x000002957BF98E00>, completion_to_prompt=<function default_completion_to_prompt at 0x000002957BFDF4C0>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model_name='mistralai/Mixtral-8x7B-Instruct-v0.1', token='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', timeout=None, headers=None, cookies=None, task=None, context_window=3900, num_output=256, is_chat_model=False, is_function_calling_model=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create llm model\n",
    "from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", token=HF_TOKEN)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb590513-fe29-49d2-aca1-12695b938051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build basic RAG system\n",
    "from llama_index.core import VectorStoreIndex\n",
    "index = VectorStoreIndex.from_documents(documents=documents, embed_model='local')\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "005aae5f-e5cc-4577-9af1-38504ddd9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from llama_index.core.llama_pack import download_llama_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e1d7ea-ed2b-48fa-a664-ff4103158d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate using the RagEvaluatorPack\n",
    "RagEvaluatorPack = download_llama_pack(\n",
    "    \"RagEvaluatorPack\", \"./rag_evaluator_pack\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6447bb98-2caa-4d93-89ad-b407a3305ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_evaluator_pack = RagEvaluatorPack(\n",
    "    rag_dataset=rag_dataset, query_engine=query_engine, judge_llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fffa8f89-abee-4623-ac69-2b224bedd737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.packs.rag_evaluator.base.RagEvaluatorPack at 0x295102b7110>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_evaluator_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fdbc631-4222-4533-9ea3-111dd87f4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_df = await rag_evaluator_pack.arun(\n",
    "#     batch_size=20,  # batches the number of openai api calls to make\n",
    "#     sleep_time_in_seconds=1,  # seconds to sleep before making an api call\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7842051-1804-425e-a889-6e8de1317c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "evaluator_model = FaithfulnessEvaluator(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c106d79-b55a-4906-a772-5e00fd81b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bc008d7-144b-4beb-85cf-c1d2c2ba9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_vector = query_engine.query(\"What is solana blockchain?\")\n",
    "eval_result = evaluator_model.evaluate_response(response=response_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f9a32e7-b343-4129-bdfd-59566534be24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSolana is a blockchain system that brings significant improvement to the performance of traditional blockchain and enables the building of scalable and user-friendly applications for the world. It retains all the attributes of traditional blockchain systems but has a much better performance. Solana introduces the Proof of History mechanism to improve the performance of traditional blockchain systems. In the Solana system, there are two types of nodes: Leader and Verifier. The Leader is an elected Proof of History generator, and Solana rotates leaders at fixed intervals. The Leader receives transactions from users and orders them into a Proof of History sequence. Proof of History is a mechanism used in Solana, where the Proof of History sequence is a list of transactions prearranged by a \"Leader\". The timestamp is embedded in this data structure, and every event has a unique hash and account along this data structure. This data structure tells us what event had come before another, and time cannot be faked or forecasted, which saves computing resources on synchronizing time.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3adc4732-5b62-4aa0-971d-1a2d13784fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450919d4-eb49-44d8-a94f-41c5a13550cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faithfulness is a measure of whether the generated answer is faithful to the retrieved contexts. In other words, it measures whether there is any hallucination in the generated answer.\n",
    "# This is useful for measuring if the response was hallucinated. The evaluator returns a score between 0 and 1, where 1 means the response is faithful to the retrieved contexts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
